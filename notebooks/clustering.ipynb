{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Clustering\n",
    "---\n",
    "\n",
    "This workflow demonstrates how to use the API to fetch trajectories and perform RMSD-based clustering for a specified number of clusters.\n",
    "\n",
    "### Workflow Steps\n",
    "1. **Download structure and trajectory files** using the API.  \n",
    "2. **Compute the RMSD matrix** for the selected trajectories.  \n",
    "3. **Perform iterative RMSD-based clustering** with a dynamic cutoff, ensuring the final number of representative structures falls within the desired range.\n",
    "\n",
    "This pipeline is employed in the paper [Mokhtari et al., 2025](https://doi.org/10.1101/2025.03.04.641377) as a pre-processing step.\n",
    "\n",
    "---\n",
    "\n",
    "For more information about this database, see our related work [*DynaRepo: The Repository of Macromolecular Conformational Dynamics*](https://doi.org/10.1101/2025.08.14.670260).\n",
    "\n",
    "**Authors:**  \n",
    "Omid Mokhtari, Emmanuelle Bignon, Hamed Khakzad, Yasaman Karami (Nancy, France)\n",
    "\n",
    "**For correspondence:** yasaman.karami@inria.fr\n",
    "\n",
    "---\n",
    "\n",
    "#### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, urllib\n",
    "from os.path import exists\n",
    "import mdtraj as md\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_BASE_URL = \"http://inria.mddbr.eu/api/rest/current\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_api (url : str) -> dict:\n",
    "    parsed_url = url.replace(\" \", \"%20\")\n",
    "    with urllib.request.urlopen(parsed_url) as response:\n",
    "        return json.loads(response.read().decode(\"utf-8\"))\n",
    "def download_file_api (url : str, filename : str):\n",
    "    parsed_url = url.replace(\" \", \"%20\")\n",
    "    urllib.request.urlretrieve(url, filename)\n",
    "    \n",
    "def gromos(traj, rmsd_matrix, cutoff, atom_indices=None):\n",
    "    n_frames = traj.n_frames\n",
    "    \n",
    "    # GROMOS clustering algorithm\n",
    "    clusters = np.full(n_frames, -1, dtype=int)  # -1 means unassigned\n",
    "    cluster_centers = []\n",
    "    cluster_id = 0\n",
    "    \n",
    "    unassigned = np.arange(n_frames)\n",
    "    \n",
    "    while len(unassigned) > 0:\n",
    "        neighbor_counts = np.zeros(len(unassigned))\n",
    "        \n",
    "        for i, frame_idx in enumerate(unassigned):\n",
    "            distances = rmsd_matrix[frame_idx, unassigned]\n",
    "            neighbor_counts[i] = np.sum(distances <= cutoff)\n",
    "        \n",
    "        center_idx = unassigned[np.argmax(neighbor_counts)]\n",
    "        cluster_centers.append(center_idx)\n",
    "        \n",
    "        distances_to_center = rmsd_matrix[center_idx, unassigned]\n",
    "        within_cutoff = unassigned[distances_to_center <= cutoff]\n",
    "        \n",
    "        clusters[within_cutoff] = cluster_id\n",
    "        \n",
    "        unassigned = np.setdiff1d(unassigned, within_cutoff)\n",
    "        cluster_id += 1\n",
    "    \n",
    "    return clusters, np.array(cluster_centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download both structure and trajectory data\n",
    "\n",
    "Change the project name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We query the API at http://inria.mddbr.eu/api/rest/current/projects/A00K6/files/structure\n",
      "Structure file has been downloaded successfully\n",
      "We query the API at http://inria.mddbr.eu/api/rest/current/projects/A00K6/files/trajectory?format=xtc\n",
      "Trajectory file has been downloaded successfully\n"
     ]
    }
   ],
   "source": [
    "project_name = 'A00K6'\n",
    "\n",
    "# Set the structure query URL for the API\n",
    "specific_project_url = API_BASE_URL + f'/projects/{project_name}'\n",
    "structure_query = specific_project_url + '/files/structure'\n",
    "print('We query the API at ' + structure_query)\n",
    "\n",
    "# Download the file with an arbitrary name\n",
    "structure_filename = 'structure.pdb'\n",
    "download_file_api(structure_query, structure_filename)\n",
    "if exists(structure_filename):\n",
    "    print('Structure file has been downloaded successfully')\n",
    "\n",
    "# Set the structure query URL for the API\n",
    "trajectory_query = specific_project_url + '/files/trajectory?format=xtc'\n",
    "print('We query the API at ' + trajectory_query)\n",
    "\n",
    "# Download the file with an arbitrary name\n",
    "trajectory_filename = 'trajectory.xtc'\n",
    "print('This may take a few seconds...', end='\\r')\n",
    "download_file_api(trajectory_query, trajectory_filename)\n",
    "if exists(trajectory_filename):\n",
    "    print('Trajectory file has been downloaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSD calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = md.load(trajectory_filename, top=structure_filename)\n",
    "# Select C-alpha atoms (like GROMACS group 3)\n",
    "atom_indices = traj.topology.select('name CA')\n",
    "\n",
    "\n",
    "# Compute RMSD matrix\n",
    "n_frames = traj.n_frames\n",
    "rmsd_matrix = np.zeros((n_frames, n_frames))\n",
    "for i in range(n_frames):\n",
    "    rmsd_matrix[i] = md.rmsd(traj, traj, frame=i, atom_indices=atom_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering completed with cutoff 0.32 and 95 clusters.\n",
      "Cluster representative structures have been saved.\n"
     ]
    }
   ],
   "source": [
    "# Adaptive GROMOS clustering\n",
    "\n",
    "cutoff = 0.15\n",
    "max_clusters = 100\n",
    "min_clusters = 10\n",
    "\n",
    "while True:\n",
    "    clusters, cluster_centers = gromos(traj, rmsd_matrix, cutoff=cutoff, atom_indices=atom_indices)\n",
    "    num_clusters = len(np.unique(clusters))\n",
    "\n",
    "    if min_clusters <= num_clusters <= max_clusters:\n",
    "        break\n",
    "    elif num_clusters < min_clusters:\n",
    "        cutoff -= 0.01\n",
    "    elif num_clusters > max_clusters:\n",
    "        cutoff += 0.01\n",
    "\n",
    "    if cutoff < 0.05 or cutoff > 1:\n",
    "        print(\"Cutoff out of range, clustering failed.\")\n",
    "        break\n",
    "\n",
    "print(f\"Clustering completed with cutoff {cutoff:.2f} and {num_clusters} clusters.\")\n",
    "\n",
    "# Save cluster representative structures\n",
    "for i, center in enumerate(cluster_centers):\n",
    "    traj[center].save_pdb(f\"cluster_{i}.pdb\")\n",
    "\n",
    "print(\"Cluster representative structures have been saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging representative conformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging cluster representatives and cleaning up the directory...\n",
      "Merged 95 clusters into cluster_representatives.pdb and cleaned up individual files.\n"
     ]
    }
   ],
   "source": [
    "print(\"Merging cluster representatives and cleaning up the directory...\")\n",
    "cluster_files = sorted(glob.glob(\"cluster_*.pdb\"), key=lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "trajectories = [md.load(f) for f in cluster_files]\n",
    "combined = md.join(trajectories)\n",
    "combined.save_pdb(\"representatives.pdb\")\n",
    "for f in cluster_files:\n",
    "    os.remove(f)\n",
    "print(f\"Merged {len(cluster_files)} clusters into cluster_representatives.pdb and cleaned up individual files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curious or stuck? Drop me a line:\n",
    "\n",
    "Omid.mokhtari@inria.fr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
